diff --git a/eval_ssd.py b/eval_ssd.py
index 5923915..e09c7e4 100644
--- a/eval_ssd.py
+++ b/eval_ssd.py
@@ -1,3 +1,8 @@
+#!/usr/bin/env python3.6
+
+''' AIMET QuantSim script on MobileNetV2-SSD Lite '''
+''' Currently We apply QuantSIm on Batch Norm folded model '''
+
 import torch
 from vision.ssd.vgg_ssd import create_vgg_ssd, create_vgg_ssd_predictor
 from vision.ssd.mobilenetv1_ssd import create_mobilenetv1_ssd, create_mobilenetv1_ssd_predictor
@@ -141,7 +146,7 @@ if __name__ == '__main__':
     elif args.net == 'sq-ssd-lite':
         net = create_squeezenet_ssd_lite(len(class_names), is_test=True)
     elif args.net == 'mb2-ssd-lite':
-        net = create_mobilenetv2_ssd_lite(len(class_names), width_mult=args.mb2_width_mult, is_test=True)
+        net = torch.load(args.trained_model)
     elif args.net == 'mb3-large-ssd-lite':
         net = create_mobilenetv3_large_ssd_lite(len(class_names), is_test=True)
     elif args.net == 'mb3-small-ssd-lite':
@@ -150,10 +155,20 @@ if __name__ == '__main__':
         logging.fatal("The net type is wrong. It should be one of vgg16-ssd, mb1-ssd and mb1-ssd-lite.")
         parser.print_help(sys.stderr)
         sys.exit(1)
+    net.eval()
+    # from IPython import embed; embed()
+    args.input_shape = (1, 3, 300, 300)
+    args.quant_scheme = "tf_enhanced"
+    args.config_file = None
+    args.default_param_bw = 8
+    args.default_output_bw = 8
 
     timer.start("Load Model")
-    net.load(args.trained_model)
     net = net.to(DEVICE)
+
+    from ssd_utils import model_eval, get_simulations
+    sim = get_simulations(net, args)
+
     print(f'It took {timer.end("Load Model")} seconds to load the model.')
     if args.net == 'vgg16-ssd':
         predictor = create_vgg_ssd_predictor(net, nms_method=args.nms_method, device=DEVICE)
@@ -164,12 +179,15 @@ if __name__ == '__main__':
     elif args.net == 'sq-ssd-lite':
         predictor = create_squeezenet_ssd_lite_predictor(net,nms_method=args.nms_method, device=DEVICE)
     elif args.net == 'mb2-ssd-lite' or args.net == "mb3-large-ssd-lite" or args.net == "mb3-small-ssd-lite":
-        predictor = create_mobilenetv2_ssd_lite_predictor(net, nms_method=args.nms_method, device=DEVICE)
+        predictor = create_mobilenetv2_ssd_lite_predictor(sim.model, nms_method=args.nms_method, device=DEVICE)
     else:
         logging.fatal("The net type is wrong. It should be one of vgg16-ssd, mb1-ssd and mb1-ssd-lite.")
         parser.print_help(sys.stderr)
         sys.exit(1)
 
+    eval_func = model_eval(args, predictor, dataset)
+    sim.compute_encodings(eval_func, (sim.model, 3000, True))
+
     results = []
     for i in range(len(dataset)):
         print("process image", i)
diff --git a/vision/ssd/ssd.py b/vision/ssd/ssd.py
index 962b9a2..d5e6676 100644
--- a/vision/ssd/ssd.py
+++ b/vision/ssd/ssd.py
@@ -24,7 +24,24 @@ class SSD(nn.Module):
         self.classification_headers = classification_headers
         self.regression_headers = regression_headers
         self.is_test = is_test
-        self.config = config
+        #self.config = config
+
+        self.image_size = 300
+        self.image_mean = np.array([127, 127, 127])  # RGB layout
+        self.image_std = 128.0
+        self.iou_threshold = 0.45
+        self.center_variance = 0.1
+        self.size_variance = 0.2
+
+        self.specs = [box_utils.SSDSpec(19, 16, box_utils.SSDBoxSizes(60, 105), [2, 3]),
+                      box_utils.SSDSpec(10, 32, box_utils.SSDBoxSizes(105, 150), [2, 3]),
+                      box_utils.SSDSpec(5, 64, box_utils.SSDBoxSizes(150, 195), [2, 3]),
+                      box_utils.SSDSpec(3, 100, box_utils.SSDBoxSizes(195, 240), [2, 3]),
+                      box_utils.SSDSpec(2, 150, box_utils.SSDBoxSizes(240, 285), [2, 3]),
+                      box_utils.SSDSpec(1, 300, box_utils.SSDBoxSizes(285, 330), [2, 3])]
+
+
+        self.gen_priors = box_utils.generate_ssd_priors(self.specs, self.image_size)
 
         # register layers in source_layer_indexes by adding them to a module list
         self.source_layer_add_ons = nn.ModuleList([t[1] for t in source_layer_indexes
@@ -34,8 +51,9 @@ class SSD(nn.Module):
         else:
             self.device = torch.device("cuda:0" if torch.cuda.is_available() else "cpu")
         if is_test:
-            self.config = config
-            self.priors = config.priors.to(self.device)
+            #self.config = config
+            #self.priors = config.priors.to(self.device)
+            self.priors = self.gen_priors.to(self.device)
             
     def forward(self, x: torch.Tensor) -> Tuple[torch.Tensor, torch.Tensor]:
         confidences = []
@@ -90,7 +108,7 @@ class SSD(nn.Module):
         if self.is_test:
             confidences = F.softmax(confidences, dim=2)
             boxes = box_utils.convert_locations_to_boxes(
-                locations, self.priors, self.config.center_variance, self.config.size_variance
+                locations.cpu(), self.priors.cpu(), self.center_variance, self.size_variance
             )
             boxes = box_utils.center_form_to_corner_form(boxes)
             return confidences, boxes
@@ -109,7 +127,9 @@ class SSD(nn.Module):
         return confidence, location
 
     def init_from_base_net(self, model):
-        self.base_net.load_state_dict(torch.load(model, map_location=lambda storage, loc: storage), strict=True)
+        state_dict = torch.load(model, map_location=lambda storage, loc: storage)
+        state_dict = {k[9:]: v for k, v in state_dict.items() if k.startswith('features')}
+        self.base_net.load_state_dict(state_dict, strict=True)
         self.source_layer_add_ons.apply(_xavier_init_)
         self.extras.apply(_xavier_init_)
         self.classification_headers.apply(_xavier_init_)
